{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.7578751,0.7780112,0.7589901], [0.15767059,0.14998941,0.18297268])\n",
    "])\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.7578751,0.7780112,0.7589901], [0.15767059,0.14998941,0.18297268])\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class DatasetLeaves(Dataset):\n",
    "    def __init__(self,mode = \"train\",prefix = \"./data/\"):\n",
    "        self.prefix = prefix\n",
    "        self.mode = mode\n",
    "        if mode == \"train\":\n",
    "            self.csv = pd.read_csv(\"./data/train_processed.csv\")\n",
    "            self.features = self.csv.loc[:,\"image\"]\n",
    "            self.targets = torch.nn.functional.one_hot(torch.tensor(self.csv.loc[:,\"label\"].values))\n",
    "        elif mode == \"test\":\n",
    "            self.csv = pd.read_csv(\"./data/titanic/titanic_train_pro.csv\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # print(idx)\n",
    "        # if idx >= len(self):\n",
    "        #     print(\"index overflow\")\n",
    "        #     return self[random.randint(0,len(self)-1)]\n",
    "        if self.mode == \"train\":\n",
    "            featrue = self.features[idx]\n",
    "            img = Image.open(self.prefix+featrue)\n",
    "            featrue = train_trans(img)\n",
    "            return featrue,self.targets[idx]\n",
    "        if self.mode == \"test\":\n",
    "            featrue = self.features[idx]\n",
    "            img = Image.open(self.prefix+featrue)\n",
    "            featrue = train_trans(img)\n",
    "            return featrue\n",
    "        #return\n",
    "\n",
    "    def show(self):\n",
    "        print(self.features)\n",
    "        print(self.targets)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get dataset Mean and Var"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# dataset = DatasetLeaves()\n",
    "# means = [0,0,0]\n",
    "# std = [0,0,0]#初始化均值和方差\n",
    "# pre_trans = transforms.Compose([\n",
    "#     transforms.Resize(224),\n",
    "#     # transforms.RandomHorizontalFlip(p=0.5),\n",
    "#     # transforms.RandomVerticalFlip(p=0.5),\n",
    "#     transforms.ToTensor()\n",
    "#     # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# ])\n",
    "# num_imgs=len(dataset)\n",
    "# for k in range(num_imgs):\n",
    "#     img,tar = dataset[k]\n",
    "#     for i in range(3):\n",
    "#         means[i] += img[i, :, :].mean()\n",
    "#         std[i] += img[i, :, :].std()\n",
    "# mean=np.array(means)/num_imgs\n",
    "# std=np.array(std)/num_imgs\n",
    "# print(mean,std)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def resnetFineTunning():\n",
    "    return 0\n",
    "\n",
    "class LeavesClassify(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(LeavesClassify,self).__init__()\n",
    "            self.resnet = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "            self.resnet.fc = nn.Linear(self.resnet.fc.in_features,176)\n",
    "            self.softmax = nn.Softmax()\n",
    "            self.fc = self.resnet.fc\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.resnet(x)\n",
    "            x = self.softmax(x)\n",
    "            return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataLoader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_dataset = DatasetLeaves()\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "net = LeavesClassify()\n",
    "\n",
    "params_backbone = [param for name,param in net.named_parameters() if name not in [\"resnet.fc.weight\",\"resnet.fc.bias\"]]\n",
    "params_classify = [param for name,param in net.fc.named_parameters()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "lossFunc = torch.nn.CrossEntropyLoss()\n",
    "lossFunc = lossFunc.cuda()\n",
    "learning_rate = 5e-3\n",
    "optimizer = torch.optim.SGD([{\n",
    "    'params': params_backbone\n",
    "},{\n",
    "    'params': params_classify,\n",
    "    'lr': learning_rate*10\n",
    "}],lr=learning_rate,momentum=0.9,weight_decay=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2152/4095942598.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lossTotal: 2940.8493824005127\n",
      "lossTotal: 2914.15016412735\n",
      "lossTotal: 2897.7526931762695\n",
      "lossTotal: 2881.0454440116882\n",
      "lossTotal: 2868.2050352096558\n",
      "lossTotal: 2856.296624660492\n",
      "lossTotal: 2849.769510269165\n",
      "lossTotal: 2837.0693707466125\n",
      "lossTotal: 2827.316967010498\n",
      "lossTotal: 2822.1395568847656\n",
      "lossTotal: 2819.4126954078674\n",
      "lossTotal: 2818.3679037094116\n",
      "lossTotal: 2817.4851059913635\n",
      "lossTotal: 2814.5605039596558\n",
      "lossTotal: 2808.991126060486\n",
      "lossTotal: 2805.3718481063843\n",
      "lossTotal: 2802.2786827087402\n",
      "lossTotal: 2797.218418598175\n",
      "lossTotal: 2790.3027029037476\n",
      "lossTotal: 2787.9153475761414\n",
      "lossTotal: 2783.687680244446\n",
      "lossTotal: 2781.917012691498\n",
      "lossTotal: 2781.094940185547\n",
      "lossTotal: 2778.16188955307\n",
      "lossTotal: 2777.5585799217224\n",
      "lossTotal: 2778.33069562912\n",
      "lossTotal: 2777.201904296875\n",
      "lossTotal: 2777.628652572632\n",
      "lossTotal: 2778.65207529068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochNum = 100\n",
    "device = \"cuda\"\n",
    "for epoch in range(epochNum):\n",
    "    lossTotal = 0\n",
    "    net.train()\n",
    "    net.cuda()\n",
    "    for i,data in enumerate(train_dataloader):\n",
    "        featrues, targets = data\n",
    "        featrues = featrues.cuda()\n",
    "        targets = targets.float().cuda()\n",
    "\n",
    "        pres = net.forward(featrues)\n",
    "        loss = lossFunc(pres,targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossTotal+= loss.item()\n",
    "    print(\"lossTotal: {}\".format(lossTotal))\n",
    "torch.save(net.state_dict(),\"./model/leaves_classify_model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}