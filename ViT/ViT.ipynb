{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "sys.path.append('../.')\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn, optim\n",
    "from torch.functional import F\n",
    "from myutils.template import train_model\n",
    "from myutils.python_and_os import ignore_warnings,PIL_load_cuncate\n",
    "\n",
    "ignore_warnings()\n",
    "PIL_load_cuncate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'project': 'ViT',\n",
    "    'lr': 1e-3,\n",
    "    'epoch': 30,\n",
    "    'batch_size':1,\n",
    "    'dataloader_shuffle': True,\n",
    "    'momentum': 0.9,\n",
    "    'device': 'cuda',\n",
    "    'save': True,\n",
    "    'save_dir': \"epoch_{}_{:.3f}.pth\",\n",
    "    'enable_wandb': True,\n",
    "    'LSTM_window': 10,\n",
    "    'DEBUG': False,\n",
    "    'LOG': True,\n",
    "    'LOG_DIR': './log.txt',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# log relocation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_path = config['LOG_DIR']\n",
    "\n",
    "if config['LOG']:\n",
    "    if os.path.exists(file_path):\n",
    "      os.remove(file_path)\n",
    "    sys.stdout = open(file_path, \"w\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyViT(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyViT,self).__init__()\n",
    "        import timm\n",
    "        raw_ViT = timm.create_model(\"vit_base_patch16_224\",pretrained=True)\n",
    "        raw_ViT_fc_ic = raw_ViT.head.in_features\n",
    "        raw_ViT.head = nn.Linear(raw_ViT_fc_ic,12)\n",
    "        self.vit = raw_ViT\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.vit(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5517767 , 0.52218217, 0.4580852 ],[0.22576344, 0.22649726, 0.23176326])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5510003 , 0.51879793, 0.45186004],[0.22197686, 0.22260648, 0.22860827])\n",
    "])\n",
    "valid_transform = transforms.Compose([\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5586525 , 0.5275879 , 0.46598247],[0.22403228, 0.22568305, 0.23144639])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dataset = ImageFolder(root='../Resnet/data/train',transform=train_transform)\n",
    "test_dataset = ImageFolder(root='../Resnet/data/test',transform=test_transform)\n",
    "valid_dataset = ImageFolder(root='../Resnet/data/valid',transform=valid_transform)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# DataLoader define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=config['batch_size'],shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "valid_dataloader = DataLoader(valid_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = MyViT()\n",
    "\n",
    "def init_model(model:nn.Module):\n",
    "    for name, i in model.named_modules():\n",
    "        if isinstance(i,nn.Linear) and \"head\" in name:\n",
    "            print(name)\n",
    "            nn.init.xavier_uniform_(i.weight)\n",
    "            nn.init.constant_(i.bias,0)\n",
    "\n",
    "init_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loss Func and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fine tune param select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "other_param = []\n",
    "head_param = []\n",
    "i = 0\n",
    "for name, param in  model.named_parameters():\n",
    "    if \"head\" in name:\n",
    "        head_param.append(param)\n",
    "    else:\n",
    "        other_param.append(param)\n",
    "    i += 1\n",
    "print(i,len(other_param),len(head_param))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss and Optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "loss_func = loss_func.to(config['device']) # using cuda\n",
    "optimizer = optim.SGD([{\n",
    "    'params': other_param,\n",
    "    'lr':0\n",
    "},{\n",
    "    'params': head_param,\n",
    "    'lr': config['lr']*10\n",
    "}],config['lr'],momentum=0.9,weight_decay=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mgeraltigas\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.2"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/geraltigas/ML/ViT/wandb/run-20220827_171311-etnhquu8</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/geraltigas/ViT/runs/etnhquu8\" target=\"_blank\">happy-rain-1</a></strong> to <a href=\"https://wandb.ai/geraltigas/ViT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|â–Œ         | 414/7195 [00:34<09:30, 11.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 69>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     68\u001B[0m     wandb\u001B[38;5;241m.\u001B[39minit(project\u001B[38;5;241m=\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproject\u001B[39m\u001B[38;5;124m'\u001B[39m],config\u001B[38;5;241m=\u001B[39mconfig)\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[0;32m---> 70\u001B[0m     epoch_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdata_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43mloss_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepoch_num\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43moutput_process\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_process\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m     test_model(config\u001B[38;5;241m=\u001B[39mconfig,model\u001B[38;5;241m=\u001B[39mmodel,test_dataLoader\u001B[38;5;241m=\u001B[39mtest_dataloader)\n",
      "File \u001B[0;32m~/ML/ViT/.././myutils/template.py:32\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(config, model, data_loader, loss_func, optimizer, epoch_num, output_process)\u001B[0m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpres and labels : \u001B[39m\u001B[38;5;124m\"\u001B[39m,pres,labels)\n\u001B[1;32m     31\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 32\u001B[0m \u001B[43mbatch_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     35\u001B[0m pbar\u001B[38;5;241m.\u001B[39mupdate(featrues\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/.conda/envs/ML/lib/python3.10/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/ML/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from myutils.plot import show_tensor\n",
    "\n",
    "\n",
    "def test_model(config:dict,model:nn.Module,test_dataLoader:DataLoader): #TODO: complete the test template code\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        num_total = 0\n",
    "        acc_total = 0\n",
    "        for i,(input,target) in enumerate(test_dataLoader):\n",
    "            input = input.to(config['device'])\n",
    "            output:torch.Tensor = model(input)\n",
    "            out_index = F.softmax(output).argmax(dim=1)\n",
    "            target = target.to(config['device'])\n",
    "            if (out_index == target)[0].item():\n",
    "                acc_total += 1\n",
    "            num_total += 1\n",
    "\n",
    "        if config['enable_wandb']:\n",
    "            wandb.log({\n",
    "                'test_acc': acc_total/num_total\n",
    "            })\n",
    "        return acc_total/num_total\n",
    "\n",
    "\n",
    "def valid_model(config:dict,model:nn.Module,test_dataLoader:DataLoader):\n",
    "    model.eval()\n",
    "    import os\n",
    "\n",
    "    reflect = ['dog','dragon','goat','horse','monkey','ox','pig','rabbit','ratt','rooster','snake','tiger']\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    with tqdm(total=len(test_dataLoader.dataset)) as pbar:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            num_total = 0\n",
    "            acc_total = 0\n",
    "            for i,(input,target) in enumerate(valid_dataset):\n",
    "                output:torch.Tensor = model(input.reshape(1,3,224,224))\n",
    "                out_index = F.softmax(output).argmax(dim=1)\n",
    "                if (out_index == target)[0].item():\n",
    "                    acc_total += 1\n",
    "                num_total += 1\n",
    "                pbar.update(1)\n",
    "                if i%20 == 0:\n",
    "                    show_tensor(input[0],reflect[out_index[0].item()])\n",
    "\n",
    "            if config['enable_wandb']:\n",
    "                wandb.log({\n",
    "                    'valid_acc': acc_total/num_total\n",
    "                })\n",
    "            return acc_total/num_total\n",
    "\n",
    "\n",
    "# process after model output and before loss func\n",
    "def output_process(output:torch.Tensor):\n",
    "\n",
    "    if len(output.shape) == 2:\n",
    "        # print(\"prediction.shape\",output.shape)\n",
    "        # print(\"prediction\",output)\n",
    "        return F.softmax(output,dim=1)\n",
    "    else:\n",
    "        # print(\"target.shape\", output.shape)\n",
    "        # print(\"target\", output)\n",
    "        return F.one_hot(output,12)\n",
    "\n",
    "if config['enable_wandb']:\n",
    "    wandb.init(project=config['project'],config=config)\n",
    "for epoch in range(config['epoch']):\n",
    "    epoch_loss = train_model(config=config,model=model,data_loader=train_dataloader,loss_func=loss_func,optimizer=optimizer,epoch_num=epoch,output_process=output_process)\n",
    "    test_model(config=config,model=model,test_dataLoader=test_dataloader)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"./checkpoints/epoch_7_376.182.pth\"))\n",
    "# print(valid_model(config=config,model=model,test_dataLoader=test_dataloader))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}